<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>{{{ PRODUCT_NAME }}}</title>
    <link rel="shortcut icon" href="TemplateData/favicon.ico">
    <link rel="stylesheet" href="TemplateData/style.css">

  </head>
  <body class="{{{ SPLASH_SCREEN_STYLE.toLowerCase() }}}">
    <div id="unity-container" class="unity-desktop">
      <canvas id="unity-canvas"></canvas>
    </div>
    <div id="loading-cover" style="display:none;">
      <div id="unity-loading-bar">
        <div id="unity-logo"><img src="logo.png"></div>
        <div id="unity-progress-bar-empty" style="display: none;">
          <div id="unity-progress-bar-full"></div>
        </div>
        <div class="spinner"></div>
      </div>
    </div>
    <div id="unity-fullscreen-button" style="display: none;"></div>
    
    <noscript id="deferred-styles">
      <link rel="stylesheet" href="fa/css/font-awesome.css">
    </noscript>
    <script>
      var loadDeferredStyles = function() {
        var addStylesNode = document.getElementById("deferred-styles");
        var replacement = document.createElement("div");
        replacement.innerHTML = addStylesNode.textContent;
        document.body.appendChild(replacement)
        addStylesNode.parentElement.removeChild(addStylesNode);
      };
      var raf = window.requestAnimationFrame || window.mozRequestAnimationFrame ||
      window.webkitRequestAnimationFrame || window.msRequestAnimationFrame;
      if (raf) raf(function() { window.setTimeout(loadDeferredStyles, 0); });
      else window.addEventListener('load', loadDeferredStyles);

      const hideFullScreenButton = "{{{ HIDE_FULL_SCREEN_BUTTON }}}";
      const buildUrl = "Build";
      const loaderUrl = buildUrl + "/{{{ LOADER_FILENAME }}}";
      const config = {
        dataUrl: buildUrl + "/{{{ DATA_FILENAME }}}",
        frameworkUrl: buildUrl + "/{{{ FRAMEWORK_FILENAME }}}",
        codeUrl: buildUrl + "/{{{ CODE_FILENAME }}}",
#if MEMORY_FILENAME
        memoryUrl: buildUrl + "/{{{ MEMORY_FILENAME }}}",
#endif
#if SYMBOLS_FILENAME
        symbolsUrl: buildUrl + "/{{{ SYMBOLS_FILENAME }}}",
#endif
        streamingAssetsUrl: "StreamingAssets",
        companyName: "{{{ COMPANY_NAME }}}",
        productName: "{{{ PRODUCT_NAME }}}",
        productVersion: "{{{ PRODUCT_VERSION }}}",
      };

      const container = document.querySelector("#unity-container");
      const canvas = document.querySelector("#unity-canvas");
      const loadingCover = document.querySelector("#loading-cover");
      const progressBarEmpty = document.querySelector("#unity-progress-bar-empty");
      const progressBarFull = document.querySelector("#unity-progress-bar-full");
      const fullscreenButton = document.querySelector("#unity-fullscreen-button");
      const spinner = document.querySelector('.spinner');

      const canFullscreen = (function() {
        return false;
        // for (const key of [
        //     'exitFullscreen',
        //     'webkitExitFullscreen',
        //     'webkitCancelFullScreen',
        //     'mozCancelFullScreen',
        //     'msExitFullscreen',
        //   ]) {
        //   if (key in document) {
        //     return true;
        //   }
        // }
        // return false;
      }());

      if (/iPhone|iPad|iPod|Android/i.test(navigator.userAgent)) {
        container.className = "unity-mobile";
        config.devicePixelRatio = 1;
      }
#if BACKGROUND_FILENAME
      canvas.style.background = "url('" + buildUrl + "/{{{ BACKGROUND_FILENAME.replace(/'/g, '%27') }}}') center / cover";
#endif
      loadingCover.style.display = "";

      const script = document.createElement("script");
      script.src = loaderUrl;
      script.onload = () => {
        createUnityInstance(canvas, config, (progress) => {
          spinner.style.display = "none";
          progressBarEmpty.style.display = "";
          progressBarFull.style.width = `${100 * progress}%`;
        }).then((unityInstance) => {
          loadingCover.style.display = "none";
          // if (canFullscreen) {
          //   if (!hideFullScreenButton) {
          //     fullscreenButton.style.display = "";
          //   }
          //   fullscreenButton.onclick = () => {
          //     unityInstance.SetFullscreen(1);
          //   };
          // }
          window.unity = unityInstance
          replaceDataSrc();
        }).catch((message) => {
          alert(message);
        });
      };
      document.body.appendChild(script);
</script>
<script>
      function openModal(idx) {
        switch (idx) {
          case 0:
            document.getElementById("cM_about").style.display = "block";
            break
          case 1:
            document.getElementById("cM_research").style.display = "block";
            break
          case 2:
            checkVideoLoaded();
            document.getElementById("cM_teaching").style.display = "block";
            break
          case 3:
            window.open("https://volcano.danbirman.com", '_blank');
            break
          case 4:
            window.unity.SendMessage("SceneControl", "ChangeScene", 1);
            break
        }
      }

      // When the user clicks anywhere outside of the modal, close it
      window.onclick = function(event) { closeCheck(event); }
      window.ontouchstart = function(event) {closeCheck(event); }

      function closeCheck(event) {
        target = event.target;
        if ((event.target.className == "close") || (event.target.className== "modal-content-big")) {
            // chain parentElements until you find the modal
            var parent = event.target.parentElement;
            while (parent.className!="modal") {
              parent = parent.parentElement;
            }
            parent.style.display = "none";
          }
          if (event.target.className == "modal") {
            event.target.style.display = "none";
          }
        
      }
      
      function replaceDataSrc() {
        [].forEach.call(document.querySelectorAll('img[data-src]'),    function(img) {
          img.setAttribute('src', img.getAttribute('data-src'));
          img.onload = function() {
            img.removeAttribute('data-src');
          };
        });
      }

      var videoLoaded = false;
      function checkVideoLoaded() {
        if (!videoLoaded) {
          document.getElementById("teachingEmbedVideo").innerHTML = "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/--sBEWfPfKA\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>";
        }
      }
    </script>

    <div id="cM_about" class="modal">

      <!-- Modal content -->
      <div class="modal-content sixty">
        <span class="close">&times;</span>
        <div style="min-height:20vh; text-align: center">
          <img src="images/dans.png" style="max-height: 40vh;">
        </div>
        <div style="min-height:40vh; text-align: center">
          <div>
            <br>
            <h2>Hi! I'm Dan, and I lead the <a rel="noopener" style="color:red" href="https://virtualbrainlab.org/"> Virtual Brain Lab</a> project creating intuitive and interactive 3D visualizations of neuroscience data.</h2>
            <br>
            <p style="color:#FF2F19">I'm on the job market looking for a tenure-track position to lead a research group working on data visualization, virtual reality psychophysics, and open-source tool development for neuroscience with close collaborations with experimentalists. Please get in touch if you think you have a position that fits!</p>
            <p>Right now, I am a Washington Research Foundation Postdoctoral Fellow in the lab of <a rel="noopener" href="http://www.steinmetzlab.net">Nick Steinmetz</a> at <span class="inline-color uw">University of Washington</span>.</p>
          </div>
        </div>
        <br>
        <br>
        <div class="center" style="min-height:10vh; text-align:center">
          <a style="text-decoration: none" href="mailto:danbirman@gmail.com"><i class="fa fa-envelope-square" aria-hidden="true"></i> Email</a>
          <br>
          <!-- <a style="text-decoration: none" href="https://twitter.com/VerticalNeuro/"><i class="fa fa-twitter" style="color:#0071FF" aria-hidden="true"></i> Twitter</a>
          <br> -->
          <a style="text-decoration: none" href="https://github.com/dbirman/"><i class="fa fa-github" aria-hidden="true"></i> Github</a>
          <br>
          <a style="text-decoration: none" href="https://scholar.google.com/citations?user=7EFz9rcAAAAJ&hl=en" aria-hidden="true"><i class="fa fa-google-plus-square" style="color:#FF2F19"></i> Publications</a>
        </div>
        <!-- invis hover images -->
        <div class="clear">
          <br>
          <hr>
          <br>
          <ul class="img-list">
            <li>
              <div>
                <img class="logo" alt="UW logo"  data-src="images/W-Logo_Purple_RGB.png"/>
                <span class="text-content"><span>University of Washington<br>Postdoc<br>2020-Present</span></span>
              </div>
            </li>
            <li>
              <div>
                <img class="logo" alt="Stanford logo"  data-src="images/SU_Seal_Red-min.png"/>
                <span class="text-content"><span>Stanford University<br>PhD Cognitive Neuroscience<br>2014-2019</span></span>
              </div>
            </li>
            <li>
              <div>
                <img class="logo" alt="BCCN logo"  data-src="images/ber2-min.png"/>
                <span class="text-content"><span>BCCN Berlin<br>Research Assistant<br>2012-2013</span></span>
              </div>
            </li>
            <li>
              <div>
                <img class="logo" alt="Cornell University logo" data-src="images/culogo.png"/>
                <span class="text-content"><span>Cornell University<br>BA Biology<br>2008-2012</span></span>
              </div>
            </li>
          </ul>
        </div>
        <br>
        <hr>
        <br>
        <div>
          <p class="copyright">&copy; Dan Birman 2023-Present . <a href="https://github.com/dbirman/web2/" rel="noopener">Code</a></p>
        </div>
      </div>
    </div>
    
  <div id="cM_research" class="modal">

    <!-- Modal content -->
    <div class="modal-content fifty">
      <span class="close">&times;</span>
      <div style="min-height:20vh; text-align: center">
        <img src="images/dans/dan_science.png" style="max-height: 30vh;">
      </div>
      <p>In the past, I studied visual attention using functional MRI, electrophysiology, and widefield calcium imaging. I now lead the <a href="https://virtualbrainlab.org" rel="noopener">Virtual Brain Lab</a>, where we are developing intuitive and interactive 3D visualization tools for neuroscience.</p>

      <h1 class="red center">Virtual Brain Lab</h1>
      <h2>Pinpoint: multi-probe trajectory planning for Neuropixels in web browsers</h2>
      <p>The scale of modern rodent neuroscience is quickly expanding beyond the capabilities of even expert experimentalists. Pinpoint brings together large-scale anatomical atlases in an intuitive 3D environment to help experimentalists plan complex multi-probe insertions. You can learn more at <a href="https://virtualbrainlab.org/pinpoint/installation_and_use.html">Pinpoint's website</a></p>

      <h2>Urchin: universal renderer for neuroscience</h2>
      <p>Neuroscience needs tools that allow researchers to quickly explore their data in its anatomical context. Urchin's intuitive API enables users to plot their data in an interactive 3D space with minimal effort. This project is just starting. You can learn more at <a href="https://virtualbrainlab.org/urchin/installation_and_use.html">Urchin's website</a></p>
      
      <h2>Glue: graphics library for Unity experiments</h2>
      <p>This project is just starting, the goal is to develop a modern 3D and virtual reality experiment framework for human, non-human primate, and rodent Psychophysics.</p>

      <h1 class="red center">International Brain Laboratory</h1>

      <p>As I've shifted to tool development, I've started to also focus more on collaborations with experimentalists whose research I can help accelerate. With the International Brain Laboratory I have helped support multiple large-scale collaborative papers, as well as build powerful interactive visualization tools for exploring large datasets</p>

      <h2>Electrophysiology atlas</h2>

      <p>With the IBL visualization team we've developed an interactive data exploration site for the upcoming electrophysiology atlas. You can check it out now: <a href="ephysatlas.internationalbrainlab.org">Ephys Atlas website</a></p>

      <h2>Brain-wide map</h2>

      <p>Preprint coming soon...</p>

      <p>In the meantime, you can explore the raw data on our <a href="https://viz.internationalbrainlab.org">interactive website</a></p>
      
      <h2>Reproducible electrophysiology</h2>

      <p>I've supported the development of the <a href="https://www.biorxiv.org/content/10.1101/2022.05.09.491042v3.abstract">reproducible electrophysiology project's</a> interactive data exploration website, check it out here: <a href="https://viz.internationalbrainlab.org/app?dset=rs&pid=e49f221d-399d-4297-bb7d-2d23cc0e4acc&tid=0&cid=257&qc=0">reproducible ephys website</a></p>

      <h1 class="red center">Visual Attention</h1>

      <p>In my research I've often build computational models that link behavior and physiology. In my most recent attention project, we developed a model of spatial attention using a convolutional neural network. What we found was that changes in tuning, such as shifts or shrinkage of receptive fields, don't account well for changes in task performance in a neural network. This suggests that they might also not be responsible for performance enhancement in human spatial attention.</p>
      
      <h3 class="red">
        Gain, not concomitant changes in spatial receptive field properties, improves task performance in a neural network attention model</h3>
      <a href="https://elifesciences.org/articles/78392">Fox, K. J.*, Birman, D.*, & Gardner, J. L. (2023). Gain, not concomitant changes in spatial receptive field properties, improves task performance in a neural network attention model. <i>eLife</i>.</a>
      <br>
      <a href="./pdfs/fox_elife_2023.pdf"><img class="paper" src="./images/pdf-icon.jpg"></a>

      <p>As a graduate student working with <a class="red" href="http://gru.stanford.edu">Justin Gardner</a> one of my major projects involved looking at how we can use motion visibility to understand how the brain "reads out" from sensory representations during perceptual decision making.</p>

      <h3 class="red">A flexible readout mechanism of human sensory representations</h3>
      <a href="https://www-nature-com.stanford.idm.oclc.org/articles/s41467-019-11448-7">Birman, D., & Gardner, J. L. (2019). A flexible readout mechanism of human sensory representations. <i>Nature Communications</i>.</a>
      <br>
      <a href="./pdfs/birman_ncomms_2019.pdf"><img class="paper" src="./images/pdf-icon.jpg"></a>

      <br>
      <h3 class="red">A quantitative framework for motion visibility in human cortex</h3>
      <a href="https://www.physiology.org/doi/abs/10.1152/jn.00433.2018">Birman, D., & Gardner, J. L. (2018). A quantitative framework for motion visibility in human cortex. <i>Journal of neurophysiology</i>.</a>
      <br>
      <a href="./pdfs/birman_jnphys_2018.pdf"><img class="paper" src="./images/pdf-icon.jpg"></a>

      <h1 class="red center">Point of No Return</h1>

      <p>In 2013 I lived in Berlin and worked in the lab of John-Dylan Haynes on this project.</p>
      <p>
        We have an intuition that we "commit" to a decision at a specific moment. Despite this intuition early neuroscience researchers found that brain activity becomes predictive of our intentions far in advance, sometimes up to 10 seconds. In this experiment we showed that in reality the <i>point of no return</i>, after which an action is guaranteed to happen, occurs only about 200 ms before motor activity. Until the point of no return the brain has not committed with no possibility of cancelling.
      </p>
      <p>
        Schultze-Kraft, M.*, Birman, D.*, Rusconi, M., Allefeld, C., Görgen, K., Dähne, S., ... & Haynes, J. D. (2015). The point of no return in vetoing self-initiated movements. <i>Proceedings of the National Academy of Sciences</i>, 201513569. *Equal author contribution. at <a href="https://sites.google.com/site/hayneslab/" rel="noopener">hayneslab</a> 
        <br>
        <a href="./pdfs/birman_pnas_2015.pdf"><img class="paper" src="./images/pdf-icon.jpg"></a>
      </p>
    </div>
  </div>

  <div id="cM_teaching" class="modal">

    <!-- Modal content -->
    <div class="modal-content fifty">
      <span class="close">&times;</span>
      <div style="min-height:20vh; text-align: center">
        <img src="images/dans/dan_teach.png" style="max-height: 30vh;">
      </div>
      <p>I have taught both introductory and upper-level neuroscience courses for undergraduates and graduate students. Among the highlights have been teaching a course I co-designed from scratch "Vertical Neuroscience" using rock climbing to introduce concepts in sensory and motor neuroscience, as well as leading a team of graduate and undergraduate teaching assistants for a 250-student introductory neuroscience class.</p>

      <h1 class="red center">Vertical Neuroscience</h1>
      <div id="teachingEmbedVideo" style="text-align:center">
      </div>

      <h1 class="red center">Teaching</h1>
      <h2>Cognitive Neuroscience</h2>
      <h4 class="red">Brain Machine Interface Seminar (NEUSCI 450)
        <span class="right">Fall 2020</span>
      </h4>
      <p>Instructor: Daniel Birman</p>

      <h4 class="red">Vertical Neuroscience (PSYCH 149s) - <a href="https://news.stanford.edu/2019/10/15/neuroscience-lens-rock-climbing/">Featured in Stanford news!</a>
        <span class="right">Summer 2019</span>
      </h4>
      <p>Instructors: Daniel Birman, Corey Fernandez</p>

      <h4 class="red">Introduction to cognitive neuroscience (PSYCH 50)
        <span class="right">Winter 2019, Winter 2018, Winter 2017, Winter 2016</span>
      </h4>
      <p>Instructor: Justin Gardner
        <br>
      Head TA: Daniel Birman
        <br>
      2019 TAs: Akshay Jagadeesh, Minyoung Lee, Jon Walters, Ian Eisenberg, Josiah Leong, Kawena Hirayama; Undergraduate TAs: Megumi Sano, Graham Todd, Greg Weaver, Vinh Ton, Kendall Costello, Michael Ko
        <br>
      2018 TAs: Akshay Jagadeesh, Minyoung Lee, Guillaume Riesen, Jon Walters; Undergraduate TAs: Emma Master, Stephanie Zhang, Kawena Hirayama, Henry Ingram, Storm Foley
        <br>
      2017 TAs: Minyoung Lee, Lior Bugatus, Zeynep Enkavi, Mona Rosenke, Guillaume Riesen
        <br>
      2016 TAs: Anna Khazenzon, Natalia Velez, Anthony Stigliani, Rosemary Le</p>

      <h4 class="red">Cognitive neuroscience - first year seminar for neuroscience graduate students (NEPR 207)
        <span class="right">Spring 2018, Spring 2017, Spring 2016</span>
      </h4>
      <p>Instructors: Russ Poldrack, Justin Gardner<br>TA: Daniel Birman</p>


      <h2>Statistics</h2>
      <h4 class="red">Methods for behavioral and social sciences (PSYCH 252)
        <span class="right">Fall 2016</span>
      </h4>
      <p>Instructors: Ewart Thomas, Benoit Monin<br>TAs: Daniel Birman, Stephanie Gagnon, Robert Hawkins</p>

      <h2>Outdoor Education</h2>

      <h4 class="red">Vertical rescue
        <span class="right">Winter 2019, Spring 2018, Winter 2018, Spring 2012, Spring 2011</span>
      </h4>
      <h4 class="red">Belaying from above and rappelling clinic
        <span class="right">Winter 2019, Fall 2018</span>
      </h4>
      <h4 class="red">Sport leading clinic
        <span class="right">Winter 2019, Fall 2018, Spring 2018, Winter 2018</span>
      </h4>
      <h4 class="red">Crack climbing clinic
        <span class="right">Fall 2017</span>
      </h4>
      <h4 class="red">Winter camping
        <span class="right">Spring 2012, 2011, 2010</span>
      </h4>
      <h4 class="red">Multipitch climbing: Red Rock
        <span class="right">Spring 2012</span>
      </h4>
      <h4 class="red">Multipitch climbing: Shawangunks
        <span class="right">Fall 2011</span>
      </h4>
      
      <h1 class="red center">Mentoring</h1>
      <h2>Research Advisor, University of Washington</h2>
      <h4 class="red">Selina Li<span class="right">2023-</span></h4>
      <h4 class="red">Jasmine Schoch<span class="right">2022-</span></h4>
      <h4 class="red">Kenneth Yang<span class="right">2022-</span></h4>
      <h4 class="red">Kai Nylund<span class="right">2021-2022</span></h4>
      <h2>Research Advisor, Stanford University</h2>
      <h4 class="red">Kai Fox<span class="right">2018-2022</span></h4>
      <h4 class="red">Aarush Selvan<span class="right">2017-2018</span></h4>
    </div>
  </div>

  </body>
</html>
